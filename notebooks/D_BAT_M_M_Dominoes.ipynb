{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx68ZZ5SJ1Sq"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nvMMSpHVimM"
      },
      "outputs": [],
      "source": [
        "!pip install colorama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIFSoPjOJF-5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import copy\n",
        "import math\n",
        "import json\n",
        "import random as rnd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as  pd\n",
        "import torchvision.utils as vision_utils\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "from colorama import Fore, Back, Style\n",
        "\n",
        "from matplotlib.ticker import NullFormatter\n",
        "\n",
        "\n",
        "DEVICE = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFhqne6NJ51A"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEDBMT3oXtlY"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDl7frtlVLBd"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def get_acc(model, dl):\n",
        "  model.eval()\n",
        "  acc = []\n",
        "  for X, y in dl:\n",
        "    acc.append((torch.sigmoid(model(X)) > 0.5) == y)\n",
        "  acc = torch.cat(acc)\n",
        "  acc = torch.sum(acc)/len(acc)\n",
        "  model.train()\n",
        "  return acc.item()\n",
        "\n",
        "\n",
        "def plot_samples(X):\n",
        "  fig = plt.figure(figsize=(8,3), dpi=130)\n",
        "  grid_img = vision_utils.make_grid(X[:13].cpu(), nrow=13, normalize=True, padding=1)\n",
        "  _ = plt.imshow(grid_img.permute(1, 2, 0), interpolation='nearest')\n",
        "  _ = plt.tick_params(axis=u'both', which=u'both',length=0)\n",
        "  ax = plt.gca()\n",
        "  _ = ax.xaxis.set_major_formatter(NullFormatter())\n",
        "  _ = ax.yaxis.set_major_formatter(NullFormatter())\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def dl_to_sampler(dl):\n",
        "  dl_iter = iter(dl)\n",
        "  def sample():\n",
        "    nonlocal dl_iter\n",
        "    try:\n",
        "      return next(dl_iter)\n",
        "    except StopIteration:\n",
        "      dl_iter = iter(dl)\n",
        "      return next(dl_iter)\n",
        "  return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MR7csp-VXhs0"
      },
      "outputs": [],
      "source": [
        "def print_stats(stats):\n",
        "\n",
        "  fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5,figsize=(16,3), dpi=110)\n",
        "  ax1.grid()\n",
        "  ax2.grid()\n",
        "  ax3.grid()\n",
        "  ax4.grid()\n",
        "  ax5.grid()\n",
        "\n",
        "  ax1.set_title(\"ERM loss\")\n",
        "  ax2.set_title(\"Adv Loss\")\n",
        "  ax3.set_title(\"Acc\")\n",
        "  ax4.set_title(\"Randomized 0/1 Acc\")\n",
        "  ax5.set_title(\"Randomized 7/9 Acc\")\n",
        "  \n",
        "  ax1.set_xlabel(\"iterations\")\n",
        "  ax2.set_xlabel(\"iterations\")\n",
        "  ax3.set_xlabel(\"iterations\")\n",
        "  ax4.set_xlabel(\"iterations\")\n",
        "  ax5.set_xlabel(\"iterations\")\n",
        "\n",
        "  for m_id, m_stats in stats.items():\n",
        "    if m_id[0] != 'm':\n",
        "      continue\n",
        "    itrs = [x[0] for x in m_stats['loss']]\n",
        "    ax1.plot(itrs, [x[1] for x in m_stats['loss']], label=m_id)\n",
        "    ax2.plot(itrs, [x[1] for x in m_stats['adv-loss']], label=m_id)\n",
        "    ax3.plot(itrs, [x[1] for x in m_stats['acc']], label=m_id)\n",
        "    ax4.plot(itrs, [x[1] for x in m_stats['r0/1-acc']], label=m_id)\n",
        "    ax5.plot(itrs, [x[1] for x in m_stats['r7/9-acc']], label=m_id)\n",
        "\n",
        "  ax3.set_ylim(0.45, 1.05)\n",
        "  ax4.set_ylim(0.45, 1.05)\n",
        "  ax5.set_ylim(0.45, 1.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "b9G8yefwjs5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "\n",
        "  def __init__(self, num_classes=10) -> None:\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "    self.fc1 = nn.Linear(960, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, num_classes)\n",
        "    self.maxPool = nn.MaxPool2d(2,2)\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    x = self.maxPool(F.relu(self.conv1(x)))\n",
        "    x = self.maxPool(F.relu(self.conv2(x)))\n",
        "    x = torch.flatten(x, start_dim=1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "EMpRciozjtFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn7tb7gnXhZ-"
      },
      "source": [
        "# Training utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bju5yztmXhqC"
      },
      "outputs": [],
      "source": [
        "def sequential_train(num_models, train_dl, valid_dl, valid_r01_dl, valid_r79_dl, test_dl, test_r01_dl, test_r79_dl, \n",
        "                     perturb_dl, alpha=10, max_epoch=100, use_diversity_reg=True, reg_model_weights=None):\n",
        "  \n",
        "  models = [LeNet(num_classes=1).to(DEVICE) for _ in range(num_models)]\n",
        "  \n",
        "  stats = {f\"m{i+1}\": {\"acc\": [], \"r0/1-acc\": [], \"r7/9-acc\": [], \"loss\": [], \"adv-loss\": []} for i in range(len(models))}\n",
        "\n",
        "  if reg_model_weights is None:\n",
        "    reg_model_weights = [1.0 for _ in range(num_models)]\n",
        "\n",
        "  for m_idx, m in enumerate(models):\n",
        "\n",
        "    opt = torch.optim.Adam(m.parameters(), lr=0.0001)\n",
        "    perturb_sampler = dl_to_sampler(perturb_dl)\n",
        "\n",
        "    for epoch in range(max_epoch):\n",
        "      for itr, (x, y) in enumerate(train_dl):\n",
        "        (x_tilde,) = perturb_sampler()\n",
        "        erm_loss = F.binary_cross_entropy_with_logits(m(x), y)\n",
        "        \n",
        "        if use_diversity_reg and m_idx != 0:\n",
        "          adv_loss = []\n",
        "          with torch.no_grad():\n",
        "            ps = [torch.sigmoid(m_(x_tilde)) for m_ in models[:m_idx]]\n",
        "          psm = torch.sigmoid(m(x_tilde))\n",
        "          for i in range(len(ps)):\n",
        "            al = - ((1.-ps[i]) * psm + ps[i] * (1.-psm) + 1e-7).log().mean()\n",
        "            adv_loss.append(al*reg_model_weights[i])\n",
        "        else:\n",
        "          adv_loss = [torch.tensor([0]).to(DEVICE)]\n",
        "\n",
        "        adv_loss = sum(adv_loss)/sum(reg_model_weights[:len(adv_loss)])\n",
        "        loss = erm_loss + alpha * adv_loss\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        if (itr + epoch * len(train_dl)) % 40 == 0:\n",
        "          itr_ = itr + epoch * len(train_dl)\n",
        "          print_str = f\"[m{m_idx+1}] {epoch}/{itr_} [train] loss: {erm_loss.item():.2f} adv-loss: {adv_loss.item():.2f} \"\n",
        "          stats[f\"m{m_idx+1}\"][\"loss\"].append((itr_, erm_loss.item()))\n",
        "          stats[f\"m{m_idx+1}\"][\"adv-loss\"].append((itr_, adv_loss.item()))\n",
        "          acc = get_acc(m, valid_dl)\n",
        "          acc_r01 = get_acc(m, valid_r01_dl)\n",
        "          acc_r79 = get_acc(m, valid_r79_dl)\n",
        "          stats[f\"m{m_idx+1}\"][\"acc\"].append((itr_, acc))\n",
        "          stats[f\"m{m_idx+1}\"][\"r0/1-acc\"].append((itr_, acc_r01))\n",
        "          stats[f\"m{m_idx+1}\"][\"r7/9-acc\"].append((itr_, acc_r79))\n",
        "          #print_str += f\"[m{i+1}] acc: {acc:.2f}, {Fore.RED} rand-7/9-acc: {acc_r79:.2f}, {Fore.BLUE} rand-0/1-acc: {acc_r01:.2f} {Style.RESET_ALL}\"\n",
        "          print_str += f\" acc: {acc:.2f}, {Fore.BLUE} r0/1-acc: {acc_r01:.2f} {Style.RESET_ALL}\"\n",
        "\n",
        "          print(print_str)\n",
        "        \n",
        "        itr += 1\n",
        "\n",
        "    test_acc = get_acc(m, test_dl)\n",
        "    test_r01_acc = get_acc(m, test_r01_dl)\n",
        "    test_r79_acc = get_acc(m, test_r79_dl)\n",
        "    stats[f\"m{m_idx+1}\"][\"test-acc\"] = test_acc\n",
        "    stats[f\"m{m_idx+1}\"][\"test-r0/1-acc\"] = test_r01_acc\n",
        "    stats[f\"m{m_idx+1}\"][\"test-r7/9-acc\"] = test_r79_acc\n",
        "    print(f\"[m{m_idx+1}] [test] acc: {test_acc:.3f}, r-acc: {test_r01_acc:.3f}\")\n",
        "\n",
        "  return stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN2tL3CjKBRO"
      },
      "source": [
        "# Build MM-Dominoes dataset $\\hat{\\mathcal{D}}$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_samples(dataset, nrow=13):\n",
        "  try:\n",
        "    X, Y = dataset.tensors\n",
        "  except:\n",
        "    (X,) = dataset.tensors\n",
        "  fig = plt.figure(figsize=(10,7), dpi=130)\n",
        "  grid_img = vision_utils.make_grid(X[:nrow].cpu(), nrow=nrow, normalize=True, padding=1, pad_value=0.1)\n",
        "  _ = plt.imshow(grid_img.permute(1, 2, 0), interpolation='nearest')\n",
        "  _ = plt.tick_params(axis=u'both', which=u'both',length=0)\n",
        "  ax = plt.gca()\n",
        "  _ = ax.xaxis.set_major_formatter(NullFormatter()) \n",
        "  _ = ax.yaxis.set_major_formatter(NullFormatter()) \n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "9Zuenbd5fFPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZwPGRlWJ552"
      },
      "outputs": [],
      "source": [
        "def keep_only_lbls(dataset, lbls):\n",
        "  lbls = {lbl: i for i, lbl in enumerate(lbls)}\n",
        "  final_X, final_Y = [], []\n",
        "  for x, y in dataset:\n",
        "    if y in lbls:\n",
        "      final_X.append(x)\n",
        "      final_Y.append(lbls[y])\n",
        "  X = torch.stack(final_X)\n",
        "  Y = torch.tensor(final_Y).float().view(-1,1) #.long()\n",
        "  return X, Y\n",
        "\n",
        "\n",
        "def merge_datasets(X1, Y1, X2, Y2, randomize_1=False, randomize_2=False, device=None):\n",
        "\n",
        "  if not randomize_1:\n",
        "    X1_0 = X1[Y1 == 0].view(-1, 1, 28, 28)\n",
        "    X1_1 = X1[Y1 == 1].view(-1, 1, 28, 28)\n",
        "  else:\n",
        "    perm = torch.randperm(len(X1))\n",
        "    X1 = X1[perm]\n",
        "    X1_0 = X1[:len(X1)//2].view(-1, 1, 28, 28)\n",
        "    X1_1 = X1[len(X1)//2:].view(-1, 1, 28, 28)\n",
        "\n",
        "  if not randomize_2:\n",
        "    X2_0 = X2[Y2 == 0].view(-1, 1, 28, 28)\n",
        "    X2_1 = X2[Y2 == 1].view(-1, 1, 28, 28)\n",
        "  else:\n",
        "    perm = torch.randperm(len(X2))\n",
        "    X2 = X2[perm]\n",
        "    X2_0 = X2[:len(X2)//2].view(-1, 1, 28, 28)\n",
        "    X2_1 = X2[len(X2)//2:].view(-1, 1, 28, 28)\n",
        "\n",
        "  final_0, final_1 = [], []\n",
        "\n",
        "  m = min(len(X1_0), len(X2_0))\n",
        "  X_0 = torch.cat((X1_0[:m], X2_0[:m]), axis=2)\n",
        "  m = min(len(X1_1), len(X2_1))\n",
        "  X_1 = torch.cat((X1_1[:m], X2_1[:m]), axis=2)\n",
        "\n",
        "  Y_0 = torch.zeros(len(X_0), 1)\n",
        "  Y_1 = torch.ones(len(X_1), 1)\n",
        "\n",
        "  X = torch.cat([X_0, X_1], dim=0)\n",
        "  Y = torch.cat([Y_0, Y_1], dim=0).float().view(-1,1)\n",
        "\n",
        "  perm = torch.randperm(len(Y))\n",
        "  X, Y = X[perm], Y[perm]\n",
        "\n",
        "  if device is not None:\n",
        "    X = X.to(device)\n",
        "    Y = Y.to(device)\n",
        "\n",
        "  return torch.utils.data.TensorDataset(X, Y)\n",
        "\n",
        "\n",
        "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "\n",
        "data_train = torchvision.datasets.MNIST('./data/mnist/', train=True, download=True, transform=transform)\n",
        "data_perturb_base, data_train, data_valid = random_split(data_train, [10000, 45000, 5000], generator=torch.Generator().manual_seed(42))\n",
        "X_train_7_9, Y_train_7_9 = keep_only_lbls(data_train, lbls=[7,9]) # harder to separate\n",
        "X_train_0_1, Y_train_0_1 = keep_only_lbls(data_train, lbls=[0,1]) # easier to separate\n",
        "\n",
        "X_valid_7_9, Y_valid_7_9 = keep_only_lbls(data_valid, lbls=[7,9]) # harder to separate\n",
        "X_valid_0_1, Y_valid_0_1 = keep_only_lbls(data_valid, lbls=[0,1]) # easier to separate\n",
        "\n",
        "data_test = torchvision.datasets.MNIST('./data/mnist/', train=False, download=True, transform=transform)\n",
        "X_test_7_9, Y_test_7_9 = keep_only_lbls(data_test, lbls=[7,9]) # harder to separate\n",
        "X_test_0_1, Y_test_0_1 = keep_only_lbls(data_test, lbls=[0,1]) # easier to separate\n",
        "\n",
        "data_train = merge_datasets(X_train_0_1, Y_train_0_1, X_train_7_9, Y_train_7_9, randomize_1=False, randomize_2=False, device=DEVICE)\n",
        "\n",
        "data_test = merge_datasets(X_test_0_1, Y_test_0_1, X_test_7_9, Y_test_7_9, randomize_1=False, randomize_2=False, device=DEVICE)\n",
        "data_test_r01 = merge_datasets(X_test_0_1, Y_test_0_1, X_test_7_9, Y_test_7_9, randomize_1=True, randomize_2=False, device=DEVICE)\n",
        "data_test_r79 = merge_datasets(X_test_0_1, Y_test_0_1, X_test_7_9, Y_test_7_9, randomize_1=False, randomize_2=True, device=DEVICE)\n",
        "\n",
        "data_valid = merge_datasets(X_valid_0_1, Y_valid_0_1, X_valid_7_9, Y_valid_7_9, randomize_1=False, randomize_2=False, device=DEVICE)\n",
        "data_valid_r01 = merge_datasets(X_valid_0_1, Y_valid_0_1, X_valid_7_9, Y_valid_7_9, randomize_1=True, randomize_2=False, device=DEVICE)\n",
        "data_valid_r79 = merge_datasets(X_valid_0_1, Y_valid_0_1, X_valid_7_9, Y_valid_7_9, randomize_1=False, randomize_2=True, device=DEVICE)\n",
        "\n",
        "train_dl = torch.utils.data.DataLoader(data_train, batch_size=256, shuffle=True)\n",
        "test_dl = torch.utils.data.DataLoader(data_test, batch_size=1024, shuffle=True)\n",
        "test_r79_dl = torch.utils.data.DataLoader(data_test_r79, batch_size=1024, shuffle=True)\n",
        "test_r01_dl = torch.utils.data.DataLoader(data_test_r01, batch_size=1024, shuffle=True)\n",
        "\n",
        "valid_dl = torch.utils.data.DataLoader(data_valid, batch_size=1024, shuffle=True)\n",
        "valid_r79_dl = torch.utils.data.DataLoader(data_valid_r79, batch_size=1024, shuffle=True)\n",
        "valid_r01_dl = torch.utils.data.DataLoader(data_valid_r01, batch_size=1024, shuffle=True)\n",
        "\n",
        "print(f\"Train length: {len(train_dl.dataset)}\")\n",
        "print(f\"Test length: {len(test_dl.dataset)}\")\n",
        "print(f\"Test length randomized 7/9: {len(test_r79_dl.dataset)}\")\n",
        "print(f\"Test length randomized 0/1: {len(test_r01_dl.dataset)}\")\n",
        "print(f\"Reserved for perturbations: {len(data_perturb_base)}\")\n",
        "\n",
        "print(\"Non-randomized dataset:\")\n",
        "plot_samples(data_train)\n",
        "\n",
        "print(\"7/9-randomized dataset:\")\n",
        "plot_samples(data_test_r79)\n",
        "\n",
        "print(\"0/1-randomized dataset:\")\n",
        "plot_samples(data_test_r01)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = data_train.tensors\n",
        "fig = plt.figure(figsize=(6,6), dpi=100)\n",
        "grid_img = vision_utils.make_grid((X[1:6]).cpu(), \n",
        "                                  nrow=5, \n",
        "                                  normalize=True, \n",
        "                                  padding=1, \n",
        "                                  pad_value=0.1)\n",
        "_ = plt.imshow(grid_img.permute(1, 2, 0), interpolation='nearest')\n",
        "ax = plt.gca()\n",
        "ax.xaxis.set_major_formatter(NullFormatter())\n",
        "ax.yaxis.set_major_formatter(NullFormatter())\n",
        "ax.tick_params(axis=u'both', which=u'both',length=0)\n",
        "plt.savefig('MM-dominoes-train.pdf', dpi = 200, bbox_inches='tight')"
      ],
      "metadata": {
        "id": "fiA4xNAbe94e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9c8CFpXIL0Y"
      },
      "source": [
        "# Experiments with $\\mathcal{D}_\\text{ood}^{(1)}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uje4UD_CIMJc"
      },
      "outputs": [],
      "source": [
        "data_test = data_perturb_base\n",
        "X_perturb_0, _ = keep_only_lbls(data_test, lbls=[0])\n",
        "X_perturb_1, _ = keep_only_lbls(data_test, lbls=[1])\n",
        "X_perturb_7, _ = keep_only_lbls(data_test, lbls=[7])\n",
        "X_perturb_9, _ = keep_only_lbls(data_test, lbls=[9])\n",
        "\n",
        "min_09 = min(len(X_perturb_0), len(X_perturb_9))\n",
        "X_perturb_09 = torch.cat((X_perturb_0[:min_09], X_perturb_9[:min_09]),  axis=2)\n",
        "min_17 = min(len(X_perturb_1), len(X_perturb_7))\n",
        "X_perturb_17 = torch.cat((X_perturb_1[:min_17], X_perturb_7[:min_17]),  axis=2)\n",
        "X_perturb = torch.cat((X_perturb_09, X_perturb_17), dim=0)\n",
        "X_perturb = X_perturb[torch.randperm(len(X_perturb))]\n",
        "\n",
        "data_perturb = torch.utils.data.TensorDataset(X_perturb.to(DEVICE))\n",
        "\n",
        "perturb_dl = torch.utils.data.DataLoader(data_perturb, batch_size=256, shuffle=True)\n",
        "\n",
        "print(f\"OOD dataset size: {len(perturb_dl.dataset)}\")\n",
        "\n",
        "print(\"OOD dataset:\")\n",
        "plot_samples(X_perturb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VrrOLkqISEc"
      },
      "outputs": [],
      "source": [
        "all_stats = []\n",
        "for _ in range(5):\n",
        "  stats = sequential_train(2, train_dl, valid_dl, valid_r01_dl, valid_r79_dl, test_dl, test_r01_dl, test_r79_dl, \n",
        "                          perturb_dl, alpha=0.1, max_epoch=200)\n",
        "  all_stats.append(stats)\n",
        "  print_stats(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnaEYnkaFdQd"
      },
      "source": [
        "# Experiments with $\\mathcal{D}_\\text{ood}^{(2)}$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_test = data_perturb_base \n",
        "X_perturb, _ = keep_only_lbls(data_test, lbls=[0,1,2,3,4,5,6,7,8,9])\n",
        "X_perturb = torch.cat((X_perturb, X_perturb[torch.randperm(len(X_perturb))]),  axis=2)\n",
        "data_perturb = torch.utils.data.TensorDataset(X_perturb.to(DEVICE))\n",
        "\n",
        "perturb_dl = torch.utils.data.DataLoader(data_perturb, batch_size=256, shuffle=True)\n",
        "\n",
        "print(f\"OOD dataset size: {len(perturb_dl.dataset)}\")\n",
        "\n",
        "print(\"OOD dataset:\")\n",
        "plot_samples(X_perturb)"
      ],
      "metadata": {
        "id": "Jo45imYOmjH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_stats = []\n",
        "for _ in range(5):\n",
        "  stats = sequential_train(2, train_dl, valid_dl, valid_r01_dl, valid_r79_dl, test_dl, test_r01_dl, test_r79_dl, \n",
        "                          perturb_dl, alpha=1.0, max_epoch=200)\n",
        "  all_stats.append(stats)\n",
        "  print_stats(stats)"
      ],
      "metadata": {
        "id": "QW9UKNdmmjLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments with $\\mathcal{D}_\\text{ood}^{(3)}$"
      ],
      "metadata": {
        "id": "6ltwcx4fqpf7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arwRPr6GFdY5"
      },
      "outputs": [],
      "source": [
        "data_test = data_perturb_base\n",
        "X_perturb_01, _ = keep_only_lbls(data_test, lbls=[0,1])\n",
        "X_perturb_ood, _ = keep_only_lbls(data_test, lbls=[2,3,4,5,6,8])\n",
        "\n",
        "min_l = min(len(X_perturb_01), len(X_perturb_ood))\n",
        "X_perturb = torch.cat((X_perturb_01[:min_l], X_perturb_ood[:min_l]),  axis=2)\n",
        "X_perturb = X_perturb[torch.randperm(len(X_perturb))]\n",
        "\n",
        "data_perturb = torch.utils.data.TensorDataset(X_perturb.to(DEVICE))\n",
        "\n",
        "perturb_dl = torch.utils.data.DataLoader(data_perturb, batch_size=256, shuffle=True)\n",
        "\n",
        "print(f\"Perturb length: {len(perturb_dl.dataset)}\")\n",
        "\n",
        "print(\"Perturbation dataset:\")\n",
        "plot_samples(X_perturb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DD5bzcTEFdbS"
      },
      "outputs": [],
      "source": [
        "all_stats = []\n",
        "for _ in range(5):\n",
        "  stats = sequential_train(2, train_dl, valid_dl, valid_r01_dl, valid_r79_dl, test_dl, test_r01_dl, test_r79_dl, \n",
        "                          perturb_dl, alpha=1.0, max_epoch=200)\n",
        "  all_stats.append(stats)\n",
        "  print_stats(stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-sPu-dK-Y4r"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fIuIkRL-Y-u"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23F-OzmL-ZAV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALAuCK9X-ZGJ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "D-BAT-M/M-Dominoes.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}