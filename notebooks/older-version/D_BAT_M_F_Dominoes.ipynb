{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOxhrofLejiY"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sBAOOgeeZmA"
      },
      "outputs": [],
      "source": [
        "!pip install colorama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfDRnCoPeo9I"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import json\n",
        "import random as rnd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils as vision_utils\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "from colorama import Fore, Back, Style\n",
        "\n",
        "from matplotlib.ticker import NullFormatter\n",
        "\n",
        "\n",
        "DEVICE = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yym65-pveo_q"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAfByEeYek9B"
      },
      "source": [
        "# Build MF-Dominoes dataset $\\hat{\\mathcal{D}}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MCgoYp5ki-V"
      },
      "outputs": [],
      "source": [
        "def plot_samples(dataset, nrow=13, figsize=(10,7)):\n",
        "  try:\n",
        "    X, Y = dataset.tensors\n",
        "  except:\n",
        "    try:\n",
        "      (X,) = dataset.tensors\n",
        "    except:\n",
        "      X = dataset\n",
        "  fig = plt.figure(figsize=figsize, dpi=130)\n",
        "  grid_img = vision_utils.make_grid(X[:nrow].cpu(), nrow=nrow, normalize=True, padding=1)\n",
        "  _ = plt.imshow(grid_img.permute(1, 2, 0), interpolation='nearest')\n",
        "  _ = plt.tick_params(axis=u'both', which=u'both',length=0)\n",
        "  ax = plt.gca()\n",
        "  _ = ax.xaxis.set_major_formatter(NullFormatter()) \n",
        "  _ = ax.yaxis.set_major_formatter(NullFormatter()) \n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def keep_only_lbls(dataset, lbls):\n",
        "  lbls = {lbl: i for i, lbl in enumerate(lbls)}\n",
        "  final_X, final_Y = [], []\n",
        "  for x, y in dataset:\n",
        "    if y in lbls:\n",
        "      final_X.append(x)\n",
        "      final_Y.append(lbls[y])\n",
        "  X = torch.stack(final_X)\n",
        "  Y = torch.tensor(final_Y).float().view(-1,1)\n",
        "  return X, Y\n",
        "\n",
        "\n",
        "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "\n",
        "mnist_train = torchvision.datasets.MNIST('./data/mnist/', train=True, download=True, transform=transform)\n",
        "fashm_train = torchvision.datasets.FashionMNIST('./data/FashionMNIST/', train=True, download=True, transform=transform)\n",
        "mnist_perturb_base, mnist_train, mnist_valid = random_split(mnist_train, [10000, 45000, 5000], generator=torch.Generator().manual_seed(42))\n",
        "fashm_perturb_base, fashm_train, fashm_valid = random_split(fashm_train, [10000, 45000, 5000], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "mnist_test = torchvision.datasets.MNIST('./data/mnist/', train=False, download=True, transform=transform)\n",
        "fashm_test = torchvision.datasets.FashionMNIST('./data/FashionMNIST/', train=False, download=True, transform=transform)\n",
        "\n",
        "def build_mf_dataset(mnist_data, fashm_data, randomize_m=False, randomize_f=False):\n",
        "  X_m_train_0, _ = keep_only_lbls(mnist_data, lbls=[0])\n",
        "  X_m_train_1, _ = keep_only_lbls(mnist_data, lbls=[1])\n",
        "  X_m_train_0 = X_m_train_0[torch.randperm(len(X_m_train_0))]\n",
        "  X_m_train_1 = X_m_train_1[torch.randperm(len(X_m_train_1))]\n",
        "\n",
        "  X_f_train_4, _ = keep_only_lbls(fashm_data, lbls=[4])\n",
        "  X_f_train_3, _ = keep_only_lbls(fashm_data, lbls=[3])\n",
        "  X_f_train_4 = X_f_train_4[torch.randperm(len(X_f_train_4))]\n",
        "  X_f_train_3 = X_f_train_3[torch.randperm(len(X_f_train_3))]\n",
        "\n",
        "  min_04 = min(len(X_m_train_0), len(X_f_train_4))\n",
        "  min_13 = min(len(X_m_train_1), len(X_f_train_3))\n",
        "  X_top = torch.cat((X_m_train_0[:min_04], X_m_train_1[:min_13]),dim=0) \n",
        "  X_bottom = torch.cat((X_f_train_4[:min_04], X_f_train_3[:min_13]),dim=0) \n",
        "  if randomize_m:\n",
        "    shuffle = torch.randperm(len(X_top))\n",
        "    X_top = X_top[shuffle]\n",
        "  if randomize_f:\n",
        "    shuffle = torch.randperm(len(X_bottom))\n",
        "    X_bottom = X_bottom[shuffle]\n",
        "  X_train = torch.cat((X_top, X_bottom), dim=2)\n",
        "  Y_train = torch.cat((torch.zeros((min_04,)), torch.ones((min_13,))))\n",
        "  shuffle = torch.randperm(len(X_train))\n",
        "  X_train = X_train[shuffle]\n",
        "  Y_train = Y_train[shuffle].float().view(-1,1)\n",
        "  data_train = torch.utils.data.TensorDataset(X_train.to(DEVICE), Y_train.to(DEVICE))\n",
        "  return data_train\n",
        "\n",
        "\n",
        "# Training / valid / test datasets\n",
        "data_train = build_mf_dataset(mnist_train, fashm_train)\n",
        "data_valid = build_mf_dataset(mnist_valid, fashm_valid)\n",
        "data_test = build_mf_dataset(mnist_test, fashm_test)\n",
        "\n",
        "train_dl = torch.utils.data.DataLoader(data_train, batch_size=256, shuffle=True)\n",
        "valid_dl = torch.utils.data.DataLoader(data_valid, batch_size=1024, shuffle=False)\n",
        "test_dl = torch.utils.data.DataLoader(data_test, batch_size=1024, shuffle=False)\n",
        "\n",
        "\n",
        "# MNIST randomized test / valid datasets\n",
        "data_test_rm = build_mf_dataset(mnist_test, fashm_test, randomize_m=True, randomize_f=False)\n",
        "data_valid_rm = build_mf_dataset(mnist_valid, fashm_valid, randomize_m=True, randomize_f=False)\n",
        "\n",
        "test_rm_dl = torch.utils.data.DataLoader(data_test_rm, batch_size=1024, shuffle=False)\n",
        "valid_rm_dl = torch.utils.data.DataLoader(data_valid_rm, batch_size=1024, shuffle=False)\n",
        "\n",
        "# F-MNIST randomized test / valid datasets\n",
        "data_test_rf = build_mf_dataset(mnist_test, fashm_test, randomize_m=False, randomize_f=True)\n",
        "data_valid_rf = build_mf_dataset(mnist_valid, fashm_valid, randomize_m=False, randomize_f=True)\n",
        "\n",
        "test_rf_dl = torch.utils.data.DataLoader(data_test_rf, batch_size=1024, shuffle=False)\n",
        "valid_rf_dl = torch.utils.data.DataLoader(data_valid_rf, batch_size=1024, shuffle=False)\n",
        "\n",
        "\n",
        "print(f\"Train length: {len(train_dl.dataset)}\")\n",
        "print(f\"Test length: {len(test_dl.dataset)}\")\n",
        "print(f\"Test length randomized mnist: {len(test_rm_dl.dataset)}\")\n",
        "print(f\"Test length randomized cifar10: {len(test_rf_dl.dataset)}\")\n",
        "\n",
        "print(\"Non-randomized train dataset:\")\n",
        "plot_samples(data_train)\n",
        "\n",
        "print(\"Non-randomized test dataset:\")\n",
        "plot_samples(data_test)\n",
        "\n",
        "print(\"MNIST-randomized test dataset:\")\n",
        "plot_samples(data_test_rm)\n",
        "\n",
        "print(\"CIFAR10-randomized test dataset:\")\n",
        "plot_samples(data_test_rf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3IAtYwOdowN"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bmj1GdVFdo5G"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def get_acc(model, dl):\n",
        "  model.eval()\n",
        "  acc = []\n",
        "  for X, y in dl:\n",
        "    acc.append((torch.sigmoid(model(X)) > 0.5) == y)\n",
        "  acc = torch.cat(acc)\n",
        "  acc = torch.sum(acc)/len(acc)\n",
        "  model.train()\n",
        "  return acc.item()\n",
        "\n",
        "\n",
        "def dl_to_sampler(dl):\n",
        "  dl_iter = iter(dl)\n",
        "  def sample():\n",
        "    nonlocal dl_iter\n",
        "    try:\n",
        "      return next(dl_iter)\n",
        "    except StopIteration:\n",
        "      dl_iter = iter(dl)\n",
        "      return next(dl_iter)\n",
        "  return sample\n",
        "\n",
        "\n",
        "def print_stats(stats):\n",
        "\n",
        "  fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5,figsize=(16,3), dpi=110)\n",
        "  ax1.grid()\n",
        "  ax2.grid()\n",
        "  ax3.grid()\n",
        "  ax4.grid()\n",
        "  ax5.grid()\n",
        "\n",
        "  ax1.set_title(\"ERM loss\")\n",
        "  ax2.set_title(\"Adv Loss\")\n",
        "  ax3.set_title(\"Acc\")\n",
        "  ax4.set_title(\"Randomized MNIST Acc\")\n",
        "  ax5.set_title(\"Randomized F-MNIST Acc\")\n",
        "  \n",
        "  ax1.set_xlabel(\"iterations\")\n",
        "  ax2.set_xlabel(\"iterations\")\n",
        "  ax3.set_xlabel(\"iterations\")\n",
        "  ax4.set_xlabel(\"iterations\")\n",
        "  ax5.set_xlabel(\"iterations\")\n",
        "\n",
        "  for m_id, m_stats in stats.items():\n",
        "    if m_id[0] != 'm':\n",
        "      continue\n",
        "    itrs = [x[0] for x in m_stats['loss']]\n",
        "    ax1.plot(itrs, [x[1] for x in m_stats['loss']], label=m_id)\n",
        "    ax2.plot(itrs, [x[1] for x in m_stats['adv-loss']], label=m_id)\n",
        "    ax3.plot(itrs, [x[1] for x in m_stats['acc']], label=m_id)\n",
        "    ax4.plot(itrs, [x[1] for x in m_stats['rm-acc']], label=m_id)\n",
        "    ax5.plot(itrs, [x[1] for x in m_stats['rf-acc']], label=m_id)\n",
        "\n",
        "  ax3.set_ylim(0.45, 1.05)\n",
        "  ax4.set_ylim(0.45, 1.05)\n",
        "  ax5.set_ylim(0.45, 1.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExUrHLZkgDFQ"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMbmcEciJija"
      },
      "outputs": [],
      "source": [
        "class LeNet(nn.Module):\n",
        "\n",
        "  def __init__(self, num_classes=10) -> None:\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "    self.fc1 = nn.Linear(960, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, num_classes)\n",
        "    self.maxPool = nn.MaxPool2d(2,2)\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    x = self.maxPool(F.relu(self.conv1(x)))\n",
        "    x = self.maxPool(F.relu(self.conv2(x)))\n",
        "    x = torch.flatten(x, start_dim=1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "    \n",
        "def set_train_mode(models):\n",
        "  for m in models:\n",
        "    m.train()\n",
        "\n",
        "\n",
        "def set_eval_mode(models):\n",
        "  for m in models:\n",
        "    m.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35E1d3WEgMs7"
      },
      "source": [
        "# Training code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzZ5mq_ZGDF6"
      },
      "outputs": [],
      "source": [
        "def sequential_train(num_models, train_dl, valid_dl, valid_rm_dl, valid_rf_dl, test_dl, test_rm_dl, test_rf_dl, \n",
        "                     perturb_dl, alpha=10, max_epoch=100, use_diversity_reg=True, reg_model_weights=None, lr=0.01, weight_decay=1e-6):\n",
        "  \n",
        "  models = [LeNet(num_classes=1).to(DEVICE) for _ in range(num_models)]\n",
        "  \n",
        "  stats = {f\"m{i+1}\": {\"acc\": [], \"rm-acc\": [], \"rf-acc\": [], \"loss\": [], \"adv-loss\": []} for i in range(len(models))}\n",
        "\n",
        "  if reg_model_weights is None:\n",
        "    reg_model_weights = [1.0 for _ in range(num_models)]\n",
        "\n",
        "  for m_idx, m in enumerate(models):\n",
        "\n",
        "    opt = torch.optim.AdamW(m.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    perturb_sampler = dl_to_sampler(perturb_dl)\n",
        "\n",
        "    for epoch in range(max_epoch):\n",
        "      for itr, (x, y) in enumerate(train_dl):\n",
        "        (x_tilde,) = perturb_sampler()\n",
        "        erm_loss = F.binary_cross_entropy_with_logits(m(x), y)\n",
        "        \n",
        "        if use_diversity_reg and m_idx != 0:\n",
        "          adv_loss = []\n",
        "          with torch.no_grad():\n",
        "            ps = [torch.sigmoid(m_(x_tilde)) for m_ in models[:m_idx]]\n",
        "          psm = torch.sigmoid(m(x_tilde))\n",
        "          for i in range(len(ps)):\n",
        "            al = - ((1.-ps[i]) * psm + ps[i] * (1.-psm) + 1e-7).log().mean()\n",
        "            adv_loss.append(al*reg_model_weights[i])\n",
        "        else:\n",
        "          adv_loss = [torch.tensor([0]).to(DEVICE)]\n",
        "\n",
        "        adv_loss = sum(adv_loss)/sum(reg_model_weights[:len(adv_loss)])\n",
        "        loss = erm_loss + alpha * adv_loss\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        if (itr + epoch * len(train_dl)) % 200 == 0:\n",
        "          itr_ = itr + epoch * len(train_dl)\n",
        "          print_str = f\"[m{m_idx+1}] {epoch}/{itr_} [train] loss: {erm_loss.item():.2f} adv-loss: {adv_loss.item():.2f} \"\n",
        "          stats[f\"m{m_idx+1}\"][\"loss\"].append((itr_, erm_loss.item()))\n",
        "          stats[f\"m{m_idx+1}\"][\"adv-loss\"].append((itr_, adv_loss.item()))\n",
        "          acc = get_acc(m, valid_dl)\n",
        "          acc_rm = get_acc(m, valid_rm_dl)\n",
        "          acc_rf = get_acc(m, valid_rf_dl)\n",
        "          stats[f\"m{m_idx+1}\"][\"acc\"].append((itr_, acc))\n",
        "          stats[f\"m{m_idx+1}\"][\"rm-acc\"].append((itr_, acc_rm))\n",
        "          stats[f\"m{m_idx+1}\"][\"rf-acc\"].append((itr_, acc_rf))\n",
        "          print_str += f\" acc: {acc:.2f}, {Fore.BLUE} rm-acc: {acc_rm:.2f} {Style.RESET_ALL}\"\n",
        "\n",
        "          print(print_str)\n",
        "        \n",
        "        itr += 1\n",
        "\n",
        "    test_acc = get_acc(m, test_dl)\n",
        "    test_rm_acc = get_acc(m, test_rm_dl)\n",
        "    test_rf_acc = get_acc(m, test_rf_dl)\n",
        "    stats[f\"m{m_idx+1}\"][\"test-acc\"] = test_acc\n",
        "    stats[f\"m{m_idx+1}\"][\"test-rm-acc\"] = test_rm_acc\n",
        "    stats[f\"m{m_idx+1}\"][\"test-rf-acc\"] = test_rf_acc\n",
        "    print(f\"[m{m_idx+1}] [test] acc: {test_acc:.3f}, r-acc: {test_rm_acc:.3f}\")\n",
        "\n",
        "  return stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQNeQPiDgccI"
      },
      "source": [
        "# Experiments with $\\mathcal{D}_\\text{ood}^{(1)}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOkPQ6JrmVhm"
      },
      "outputs": [],
      "source": [
        "mnist_test = mnist_perturb_base\n",
        "fashm_test = fashm_perturb_base\n",
        "\n",
        "X_m_test_0, _ = keep_only_lbls(mnist_test, lbls=[0])\n",
        "X_m_test_1, _ = keep_only_lbls(mnist_test, lbls=[1])\n",
        "\n",
        "X_c_test_1, _ = keep_only_lbls(fashm_test, lbls=[4])\n",
        "X_c_test_9, _ = keep_only_lbls(fashm_test, lbls=[3])\n",
        "X_c_test_1 = X_c_test_1[torch.randperm(len(X_c_test_1))]\n",
        "X_c_test_9 = X_c_test_9[torch.randperm(len(X_c_test_9))]\n",
        "\n",
        "min_09 = min(len(X_m_test_0), len(X_c_test_9))\n",
        "X_perturb_09 = torch.cat((X_m_test_0[:min_09], X_c_test_9[:min_09]),  axis=2)\n",
        "min_11 = min(len(X_m_test_1), len(X_c_test_1))\n",
        "X_perturb_11 = torch.cat((X_m_test_1[:min_11], X_c_test_1[:min_11]),  axis=2)\n",
        "X_perturb = torch.cat((X_perturb_09, X_perturb_11), dim=0)\n",
        "X_perturb = X_perturb[torch.randperm(len(X_perturb))]\n",
        "\n",
        "data_perturb = torch.utils.data.TensorDataset(X_perturb.to(DEVICE))\n",
        "\n",
        "perturb_dl = torch.utils.data.DataLoader(data_perturb, batch_size=256, shuffle=True)\n",
        "\n",
        "print(f\"OOD dataset size: {len(perturb_dl.dataset)}\")\n",
        "\n",
        "print(\"OOD dataset:\")\n",
        "plot_samples(data_perturb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_stats = []\n",
        "for _ in range(5):\n",
        "  stats = sequential_train(2, train_dl, valid_dl, valid_rm_dl, valid_rf_dl, test_dl, test_rm_dl, test_rf_dl, \n",
        "                          perturb_dl, alpha=0.2, max_epoch=200, lr=0.0001)\n",
        "  all_stats.append(stats)\n",
        "  print_stats(stats)"
      ],
      "metadata": {
        "id": "SulaXr-iTySo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments with $\\mathcal{D}_\\text{ood}^{(2)}$"
      ],
      "metadata": {
        "id": "dcsH5R3rX4Hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_test = mnist_perturb_base\n",
        "fashm_test = fashm_perturb_base\n",
        "\n",
        "X_m_test, _ = keep_only_lbls(mnist_test, lbls=[0,1,2,3,4,5,6,7,8,9])\n",
        "X_m_test = X_m_test[torch.randperm(len(X_m_test))]\n",
        "\n",
        "X_c_test, _ = keep_only_lbls(fashm_test, lbls=[0,1,2,3,4,5,6,7,8,9])\n",
        "X_c_test = X_c_test[torch.randperm(len(X_c_test))]\n",
        "\n",
        "min_l = min(len(X_m_test), len(X_c_test))\n",
        "X_perturb = torch.cat((X_m_test[:min_l], X_c_test[:min_l]),  axis=2)\n",
        "\n",
        "data_perturb = torch.utils.data.TensorDataset(X_perturb.to(DEVICE))\n",
        "\n",
        "perturb_dl = torch.utils.data.DataLoader(data_perturb, batch_size=256, shuffle=True)\n",
        "\n",
        "print(f\"OOD dataset size: {len(perturb_dl.dataset)}\")\n",
        "\n",
        "print(\"OOD dataset:\")\n",
        "plot_samples(data_perturb)"
      ],
      "metadata": {
        "id": "pvJHBT8DX4Tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_stats = []\n",
        "for _ in range(5):\n",
        "  stats = sequential_train(2, train_dl, valid_dl, valid_rm_dl, valid_rf_dl, test_dl, test_rm_dl, test_rf_dl, \n",
        "                          perturb_dl, alpha=1, max_epoch=200, lr=0.0001)\n",
        "  all_stats.append(stats)\n",
        "  print_stats(stats)"
      ],
      "metadata": {
        "id": "7ybNm9PYX4ZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHYrqop8sm5O"
      },
      "source": [
        "# Experiments with $\\mathcal{D}_\\text{ood}^{(3)}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nglVCONCfD9P"
      },
      "outputs": [],
      "source": [
        "mnist_test = mnist_perturb_base\n",
        "fashm_test = fashm_perturb_base\n",
        "\n",
        "X_m_test_0, _ = keep_only_lbls(mnist_test, lbls=[0])\n",
        "X_m_test_1, _ = keep_only_lbls(mnist_test, lbls=[1])\n",
        "X_m_test_0 = X_m_test_0[torch.randperm(len(X_m_test_0))]\n",
        "X_m_test_1 = X_m_test_1[torch.randperm(len(X_m_test_1))]\n",
        "\n",
        "X_c_test_ood, _ = keep_only_lbls(fashm_test, lbls=[0,1,2,5,6,7,8,9])\n",
        "X_c_test_ood = X_c_test_ood[torch.randperm(len(X_c_test_ood))]\n",
        "\n",
        "K = int((len(X_c_test_ood) / len(X_m_test_0)) // 2)\n",
        "X_m_test_0 = torch.cat([X_m_test_0 for _ in range(K)], dim=0)\n",
        "X_m_test_1 = torch.cat([X_m_test_1 for _ in range(K)], dim=0)\n",
        "X_perturb_0ood = torch.cat((X_m_test_0, X_c_test_ood[:len(X_m_test_0)]),  axis=2)\n",
        "X_perturb_1ood = torch.cat((X_m_test_1, X_c_test_ood[-len(X_m_test_1):]),  axis=2)\n",
        "X_perturb = torch.cat((X_perturb_0ood, X_perturb_1ood), dim=0)\n",
        "X_perturb = X_perturb[torch.randperm(len(X_perturb))]\n",
        "\n",
        "data_perturb = torch.utils.data.TensorDataset(X_perturb.to(DEVICE))\n",
        "\n",
        "perturb_dl = torch.utils.data.DataLoader(data_perturb, batch_size=256, shuffle=True)\n",
        "\n",
        "print(f\"OOD dataset size: {len(perturb_dl.dataset)}\")\n",
        "\n",
        "print(\"OOD dataset:\")\n",
        "plot_samples(data_perturb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCRhrFqAIKdU"
      },
      "outputs": [],
      "source": [
        "all_stats = []\n",
        "for _ in range(5):\n",
        "  stats = sequential_train(2, train_dl, valid_dl, valid_rm_dl, valid_rf_dl, test_dl, test_rm_dl, test_rf_dl, \n",
        "                          perturb_dl, alpha=1.0, max_epoch=200, lr=0.0001)\n",
        "  all_stats.append(stats)\n",
        "  print_stats(stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wh1jgkekGdkT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fw5UWPKuGdne"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "D-BAT-M/F-Dominoes.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}