{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "D-BAT-MC-Dominoes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "jOxhrofLejiY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sBAOOgeeZmA"
      },
      "outputs": [],
      "source": [
        "!pip install colorama"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import json\n",
        "import random as rnd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as  pd\n",
        "import torchvision.utils as vision_utils\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "from colorama import Fore, Back, Style\n",
        "from matplotlib.ticker import NullFormatter\n",
        "\n",
        "\n",
        "DEVICE = torch.device('cuda')"
      ],
      "metadata": {
        "id": "HfDRnCoPeo9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "yym65-pveo_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build MC-Dominoes dataset"
      ],
      "metadata": {
        "id": "gAfByEeYek9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_samples(dataset, nrow=13, figsize=(10,7)):\n",
        "  try:\n",
        "    X, Y = dataset.tensors\n",
        "  except:\n",
        "    try:\n",
        "      (X,) = dataset.tensors\n",
        "    except:\n",
        "      X = dataset\n",
        "  fig = plt.figure(figsize=figsize, dpi=130)\n",
        "  grid_img = vision_utils.make_grid(X[:nrow].cpu(), nrow=nrow, normalize=True, padding=1)\n",
        "  _ = plt.imshow(grid_img.permute(1, 2, 0), interpolation='nearest')\n",
        "  _ = plt.tick_params(axis=u'both', which=u'both',length=0)\n",
        "  ax = plt.gca()\n",
        "  _ = ax.xaxis.set_major_formatter(NullFormatter()) \n",
        "  _ = ax.yaxis.set_major_formatter(NullFormatter()) \n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def keep_only_lbls(dataset, lbls):\n",
        "  lbls = {lbl: i for i, lbl in enumerate(lbls)}\n",
        "  final_X, final_Y = [], []\n",
        "  for x, y in dataset:\n",
        "    if y in lbls:\n",
        "      final_X.append(x)\n",
        "      final_Y.append(lbls[y])\n",
        "  X = torch.stack(final_X)\n",
        "  Y = torch.tensor(final_Y).float().view(-1,1)\n",
        "  return X, Y\n",
        "\n",
        "\n",
        "def format_mnist(imgs):\n",
        "  imgs = np.stack([np.pad(imgs[i][0], 2, constant_values=0)[None,:] for i in range(len(imgs))])\n",
        "  imgs = np.repeat(imgs, 3, axis=1)\n",
        "  return torch.tensor(imgs)\n",
        "\n",
        "\n",
        "def build_mc_dataset(mnist_data, cifar_data, randomize_m=False, randomize_c=False):\n",
        "  X_m_train_0, _ = keep_only_lbls(mnist_data, lbls=[0])\n",
        "  X_m_train_1, _ = keep_only_lbls(mnist_data, lbls=[1])\n",
        "  X_m_train_0 = format_mnist(X_m_train_0.view(-1, 1, 28, 28))\n",
        "  X_m_train_1 = format_mnist(X_m_train_1.view(-1, 1, 28, 28))\n",
        "  X_m_train_0 = X_m_train_0[torch.randperm(len(X_m_train_0))]\n",
        "  X_m_train_1 = X_m_train_1[torch.randperm(len(X_m_train_1))]\n",
        "\n",
        "  X_c_train_1, _ = keep_only_lbls(cifar_data, lbls=[1])\n",
        "  X_c_train_9, _ = keep_only_lbls(cifar_data, lbls=[9])\n",
        "  X_c_train_1 = X_c_train_1[torch.randperm(len(X_c_train_1))]\n",
        "  X_c_train_9 = X_c_train_9[torch.randperm(len(X_c_train_9))]\n",
        "\n",
        "  min_01 = min(len(X_m_train_0), len(X_c_train_1))\n",
        "  min_19 = min(len(X_m_train_1), len(X_c_train_9))\n",
        "  X_top = torch.cat((X_m_train_0[:min_01], X_m_train_1[:min_19]),dim=0) \n",
        "  X_bottom = torch.cat((X_c_train_1[:min_01], X_c_train_9[:min_19]),dim=0) \n",
        "  if randomize_m:\n",
        "    shuffle = torch.randperm(len(X_top))\n",
        "    X_top = X_top[shuffle]\n",
        "  if randomize_c:\n",
        "    shuffle = torch.randperm(len(X_bottom))\n",
        "    X_bottom = X_bottom[shuffle]\n",
        "  X_train = torch.cat((X_top, X_bottom), dim=2)\n",
        "  Y_train = torch.cat((torch.zeros((min_01,)), torch.ones((min_19,))))\n",
        "  shuffle = torch.randperm(len(X_train))\n",
        "  X_train = X_train[shuffle]\n",
        "  Y_train = Y_train[shuffle].float().view(-1,1)\n",
        "  data_train = torch.utils.data.TensorDataset(X_train.to(DEVICE), Y_train.to(DEVICE))\n",
        "  return data_train\n",
        "\n",
        "\n",
        "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "\n",
        "mnist_train = torchvision.datasets.MNIST('./data/mnist/', train=True, download=True, transform=transform)\n",
        "cifar_train = torchvision.datasets.CIFAR10('./data/cifar10/', train=True, download=True, transform=transform)\n",
        "mnist_perturb_base, mnist_train, mnist_valid = random_split(mnist_train, [10000, 45000, 5000], generator=torch.Generator().manual_seed(42))\n",
        "cifar_perturb_base, cifar_train, cifar_valid = random_split(cifar_train, [10000, 35000, 5000], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "mnist_test = torchvision.datasets.MNIST('./data/mnist/', train=False, download=True, transform=transform)\n",
        "cifar_test = torchvision.datasets.CIFAR10('./data/FashionMNIST/', train=False, download=True, transform=transform)\n",
        "\n",
        "\n",
        "# Training / valid / test datasets\n",
        "data_train = build_mc_dataset(mnist_train, cifar_train)\n",
        "data_valid = build_mc_dataset(mnist_valid, cifar_valid)\n",
        "data_test = build_mc_dataset(mnist_test, cifar_test)\n",
        "\n",
        "train_dl = torch.utils.data.DataLoader(data_train, batch_size=256, shuffle=True)\n",
        "valid_dl = torch.utils.data.DataLoader(data_valid, batch_size=1024, shuffle=False)\n",
        "test_dl = torch.utils.data.DataLoader(data_test, batch_size=1024, shuffle=False)\n",
        "\n",
        "\n",
        "# MNIST randomized test / valid datasets\n",
        "data_test_rm = build_mc_dataset(mnist_test, cifar_test, randomize_m=True, randomize_c=False)\n",
        "data_valid_rm = build_mc_dataset(mnist_valid, cifar_valid, randomize_m=True, randomize_c=False)\n",
        "\n",
        "test_rm_dl = torch.utils.data.DataLoader(data_test_rm, batch_size=1024, shuffle=False)\n",
        "valid_rm_dl = torch.utils.data.DataLoader(data_valid_rm, batch_size=1024, shuffle=False)\n",
        "\n",
        "# F-MNIST randomized test / valid datasets\n",
        "data_test_rc = build_mc_dataset(mnist_test, cifar_test, randomize_m=False, randomize_c=True)\n",
        "data_valid_rc = build_mc_dataset(mnist_valid, cifar_valid, randomize_m=False, randomize_c=True)\n",
        "\n",
        "test_rc_dl = torch.utils.data.DataLoader(data_test_rc, batch_size=1024, shuffle=False)\n",
        "valid_rc_dl = torch.utils.data.DataLoader(data_valid_rc, batch_size=1024, shuffle=False)\n",
        "\n",
        "print(f\"Train length: {len(train_dl.dataset)}\")\n",
        "print(f\"Test length: {len(test_dl.dataset)}\")\n",
        "print(f\"Test length randomized mnist: {len(test_rm_dl.dataset)}\")\n",
        "print(f\"Test length randomized cifar10: {len(test_rc_dl.dataset)}\")\n",
        "\n",
        "print(\"Non-randomized train dataset:\")\n",
        "plot_samples(data_train)\n",
        "\n",
        "print(\"Non-randomized test dataset:\")\n",
        "plot_samples(data_test)\n",
        "\n",
        "print(\"MNIST-randomized test dataset:\")\n",
        "plot_samples(data_test_rm)\n",
        "\n",
        "print(\"CIFAR10-randomized test dataset:\")\n",
        "plot_samples(data_test_rc)"
      ],
      "metadata": {
        "id": "8MCgoYp5ki-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "j3IAtYwOdowN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def get_acc(model, dl):\n",
        "  model.eval()\n",
        "  acc = []\n",
        "  for X, y in dl:\n",
        "    acc.append((torch.sigmoid(model(X)) > 0.5) == y)\n",
        "  acc = torch.cat(acc)\n",
        "  acc = torch.sum(acc)/len(acc)\n",
        "  model.train()\n",
        "  return acc.item()\n",
        "\n",
        "\n",
        "def dl_to_sampler(dl):\n",
        "  dl_iter = iter(dl)\n",
        "  def sample():\n",
        "    nonlocal dl_iter\n",
        "    try:\n",
        "      return next(dl_iter)\n",
        "    except StopIteration:\n",
        "      dl_iter = iter(dl)\n",
        "      return next(dl_iter)\n",
        "  return sample\n",
        "\n",
        "\n",
        "def print_stats(stats):\n",
        "\n",
        "  fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5,figsize=(16,3), dpi=110)\n",
        "  ax1.grid()\n",
        "  ax2.grid()\n",
        "  ax3.grid()\n",
        "  ax4.grid()\n",
        "  ax5.grid()\n",
        "\n",
        "  ax1.set_title(\"ERM loss\")\n",
        "  ax2.set_title(\"Adv Loss\")\n",
        "  ax3.set_title(\"Acc\")\n",
        "  ax4.set_title(\"Randomized MNIST Acc\")\n",
        "  ax5.set_title(\"Randomized CIFAR Acc\")\n",
        "  \n",
        "  ax1.set_xlabel(\"iterations\")\n",
        "  ax2.set_xlabel(\"iterations\")\n",
        "  ax3.set_xlabel(\"iterations\")\n",
        "  ax4.set_xlabel(\"iterations\")\n",
        "  ax5.set_xlabel(\"iterations\")\n",
        "\n",
        "  for m_id, m_stats in stats.items():\n",
        "    if m_id[0] != 'm':\n",
        "      continue\n",
        "    itrs = [x[0] for x in m_stats['loss']]\n",
        "    ax1.plot(itrs, [x[1] for x in m_stats['loss']], label=m_id)\n",
        "    ax2.plot(itrs, [x[1] for x in m_stats['adv-loss']], label=m_id)\n",
        "    ax3.plot(itrs, [x[1] for x in m_stats['acc']], label=m_id)\n",
        "    ax4.plot(itrs, [x[1] for x in m_stats['rm-acc']], label=m_id)\n",
        "    ax5.plot(itrs, [x[1] for x in m_stats['rc-acc']], label=m_id)\n",
        "\n",
        "  ax3.set_ylim(0.45, 1.05)\n",
        "  ax4.set_ylim(0.45, 1.05)\n",
        "  ax5.set_ylim(0.45, 1.05)"
      ],
      "metadata": {
        "id": "Bmj1GdVFdo5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "ExUrHLZkgDFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=10, dropout_p=0.0) -> None:\n",
        "        super().__init__()\n",
        "        self.droput_p = dropout_p\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(32, 56, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(2016, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.avgpool_2 = nn.AvgPool2d(kernel_size=2)\n",
        "        self.avgpool_3 = nn.AvgPool2d(kernel_size=3)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, dropout=True) -> torch.Tensor:\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = F.dropout(x, p=self.droput_p, training=dropout)\n",
        "        x = self.avgpool_2(x)\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = F.dropout(x, p=self.droput_p, training=dropout)\n",
        "        x = self.avgpool_3(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = F.dropout(x, p=self.droput_p, training=dropout)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = F.dropout(x, p=self.droput_p, training=dropout)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    \n",
        "def set_train_mode(models):\n",
        "  for m in models:\n",
        "    m.train()\n",
        "\n",
        "\n",
        "def set_eval_mode(models):\n",
        "  for m in models:\n",
        "    m.eval()"
      ],
      "metadata": {
        "id": "CMbmcEciJija"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training code"
      ],
      "metadata": {
        "id": "35E1d3WEgMs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_models_on_x_perturb(models, x_tilde):\n",
        "  for x in x_tilde:\n",
        "    x = x.unsqueeze(0)\n",
        "    plot_samples(x, nrow=1, figsize=(1,2))\n",
        "    for idx, m in enumerate(models):\n",
        "      probas = torch.sigmoid(m(x))[0]\n",
        "      print(f\"[m{idx+1} probas for sample:{1-probas[0].item():.3f}, {probas[0].item():.3f}\")\n",
        "\n",
        "\n",
        "def sequential_train(num_models, train_dl, valid_dl, valid_rm_dl, valid_rc_dl, test_dl, test_rm_dl, \n",
        "                     test_rc_dl, perturb_dl, alpha=10, max_epoch=100, opt='SGD',\n",
        "                     use_diversity_reg=True, reg_model_weights=None, lr_max=0.2, weight_decay=1e-5, use_scheduler=True):\n",
        "  \n",
        "  models = [LeNet(num_classes=1).to(DEVICE) for _ in range(num_models)]\n",
        "  set_train_mode(models)\n",
        "  \n",
        "  stats = {f\"m{i+1}\": {\"acc\": [], \"rm-acc\": [], \"rc-acc\": [], \"loss\": [], \"adv-loss\": []} for i in range(len(models))}\n",
        "\n",
        "  if reg_model_weights is None:\n",
        "    reg_model_weights = [1.0 for _ in range(num_models)]\n",
        "\n",
        "  for m_idx, m in enumerate(models):\n",
        "\n",
        "    if opt == 'SGD':\n",
        "      opt = torch.optim.SGD(m.parameters(), lr=lr_max, momentum=0.9, weight_decay=weight_decay)\n",
        "    else:\n",
        "      opt = torch.optim.AdamW(m.parameters(), lr=lr_max, weight_decay=weight_decay)\n",
        "    if use_scheduler:\n",
        "      scheduler = torch.optim.lr_scheduler.CyclicLR(opt, 0, lr_max, step_size_up=(len(train_dl)*max_epoch)//2, \n",
        "                                                    mode='triangular', cycle_momentum=False)\n",
        "    else:\n",
        "      scheduler = None\n",
        "    perturb_sampler = dl_to_sampler(perturb_dl)\n",
        "\n",
        "    for epoch in range(max_epoch):\n",
        "      for itr, (x, y) in enumerate(train_dl):\n",
        "        (x_tilde,) = perturb_sampler()\n",
        "        erm_loss = F.binary_cross_entropy_with_logits(m(x), y)\n",
        "        \n",
        "        if use_diversity_reg and m_idx != 0:\n",
        "          adv_loss = []\n",
        "          with torch.no_grad():\n",
        "            set_eval_mode(models)\n",
        "            ps = [torch.sigmoid(m_(x_tilde)) for m_ in models[:m_idx]]\n",
        "            set_train_mode(models)\n",
        "          psm = torch.sigmoid(m(x_tilde))\n",
        "          for i in range(len(ps)):\n",
        "            al = - ((1.-ps[i]) * psm + ps[i] * (1.-psm) + 1e-7).log().mean()\n",
        "            adv_loss.append(al*reg_model_weights[i])\n",
        "        else:\n",
        "          adv_loss = [torch.tensor([0]).to(DEVICE)]\n",
        "\n",
        "        adv_loss = sum(adv_loss)/sum(reg_model_weights[:len(adv_loss)])\n",
        "        loss = erm_loss + alpha * adv_loss\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "\n",
        "        if (itr + epoch * len(train_dl)) % 200 == 0:\n",
        "          set_eval_mode(models)\n",
        "          itr_ = itr + epoch * len(train_dl)\n",
        "          print_str = f\"[m{m_idx+1}] {epoch}/{itr_} [train] loss: {erm_loss.item():.2f} adv-loss: {adv_loss.item():.2f} \"\n",
        "          if itr_ != 0 and scheduler is not None:\n",
        "            print_str += f\"[lr] {scheduler.get_last_lr()[0]:.5f} \"\n",
        "          stats[f\"m{m_idx+1}\"][\"loss\"].append((itr_, erm_loss.item()))\n",
        "          stats[f\"m{m_idx+1}\"][\"adv-loss\"].append((itr_, adv_loss.item()))\n",
        "          acc = get_acc(m, valid_dl)\n",
        "          acc_rm = get_acc(m, valid_rm_dl)\n",
        "          acc_rc = get_acc(m, valid_rc_dl)\n",
        "          stats[f\"m{m_idx+1}\"][\"acc\"].append((itr_, acc))\n",
        "          stats[f\"m{m_idx+1}\"][\"rm-acc\"].append((itr_, acc_rm))\n",
        "          stats[f\"m{m_idx+1}\"][\"rc-acc\"].append((itr_, acc_rc))\n",
        "          print_str += f\" acc: {acc:.2f}, {Fore.BLUE} r0/1-acc: {acc_rm:.2f} {Style.RESET_ALL}\"\n",
        "          set_train_mode(models)\n",
        "          print(print_str)\n",
        "        \n",
        "        itr += 1\n",
        "\n",
        "    test_acc = get_acc(m, test_dl)\n",
        "    test_rm_acc = get_acc(m, test_rm_dl)\n",
        "    test_rc_acc = get_acc(m, test_rc_dl)\n",
        "    stats[f\"m{m_idx+1}\"][\"test-acc\"] = test_acc\n",
        "    stats[f\"m{m_idx+1}\"][\"test-rm-acc\"] = test_rm_acc\n",
        "    stats[f\"m{m_idx+1}\"][\"test-rc-acc\"] = test_rc_acc\n",
        "    print(f\"[m{m_idx+1}] [test] acc: {test_acc:.3f}, r-acc: {test_rm_acc:.3f}\")\n",
        "\n",
        "  return stats"
      ],
      "metadata": {
        "id": "QzZ5mq_ZGDF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments with $\\mathcal{D}_\\text{ood}^{(1)}$"
      ],
      "metadata": {
        "id": "QQNeQPiDgccI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_test = mnist_perturb_base\n",
        "cifar_test = cifar_perturb_base\n",
        "\n",
        "X_m_test_0, _ = keep_only_lbls(mnist_test, lbls=[0])\n",
        "X_m_test_1, _ = keep_only_lbls(mnist_test, lbls=[1])\n",
        "X_m_test_0 = format_mnist(X_m_test_0.view(-1, 1, 28, 28))[torch.randperm(len(X_m_test_0))]\n",
        "X_m_test_1 = format_mnist(X_m_test_1.view(-1, 1, 28, 28))[torch.randperm(len(X_m_test_1))]\n",
        "\n",
        "X_c_test_1, _ = keep_only_lbls(cifar_test, lbls=[1])\n",
        "X_c_test_9, _ = keep_only_lbls(cifar_test, lbls=[9])\n",
        "X_c_test_1 = X_c_test_1[torch.randperm(len(X_c_test_1))]\n",
        "X_c_test_9 = X_c_test_9[torch.randperm(len(X_c_test_9))]\n",
        "\n",
        "min_09 = min(len(X_m_test_0), len(X_c_test_9))\n",
        "X_perturb_09 = torch.cat((X_m_test_0[:min_09], X_c_test_9[:min_09]),  axis=2)\n",
        "min_11 = min(len(X_m_test_1), len(X_c_test_1))\n",
        "X_perturb_11 = torch.cat((X_m_test_1[:min_11], X_c_test_1[:min_11]),  axis=2)\n",
        "X_perturb = torch.cat((X_perturb_09, X_perturb_11), dim=0)\n",
        "X_perturb = X_perturb[torch.randperm(len(X_perturb))]\n",
        "\n",
        "data_perturb = torch.utils.data.TensorDataset(X_perturb.to(DEVICE))\n",
        "\n",
        "perturb_dl = torch.utils.data.DataLoader(data_perturb, batch_size=256, shuffle=True)\n",
        "\n",
        "print(f\"OOD dataset size: {len(perturb_dl.dataset)}\")\n",
        "\n",
        "print(\"OOD dataset:\")\n",
        "plot_samples(data_perturb)"
      ],
      "metadata": {
        "id": "iOkPQ6JrmVhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_stats = []\n",
        "for _ in range(5):\n",
        "  stats = sequential_train(2, train_dl, valid_dl, valid_rm_dl, valid_rc_dl, test_dl, test_rm_dl, test_rc_dl, \n",
        "                          perturb_dl, alpha=0.1, max_epoch=200, lr_max=0.01)\n",
        "  all_stats.append(stats)\n",
        "  print_stats(stats)"
      ],
      "metadata": {
        "id": "yRCf_G76elvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments with $\\mathcal{D}_\\text{ood}^{(2)}$"
      ],
      "metadata": {
        "id": "zYOM2OZNp25o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_test = mnist_perturb_base\n",
        "cifar_test = cifar_perturb_base\n",
        "\n",
        "X_m_test, _ = keep_only_lbls(mnist_test, lbls=[0,1,2,3,4,5,6,7,8,9])\n",
        "X_m_test = format_mnist(X_m_test.view(-1, 1, 28, 28))[torch.randperm(len(X_m_test))]\n",
        "\n",
        "X_c_test, _ = keep_only_lbls(cifar_test, lbls=[0,1,2,3,4,5,6,7,8,9])\n",
        "X_c_test = X_c_test[torch.randperm(len(X_c_test))]\n",
        "\n",
        "min_l = min(len(X_m_test), len(X_c_test))\n",
        "X_perturb = torch.cat((X_m_test[:min_l], X_c_test[:min_l]),  axis=2)\n",
        "\n",
        "data_perturb = torch.utils.data.TensorDataset(X_perturb.to(DEVICE))\n",
        "\n",
        "perturb_dl = torch.utils.data.DataLoader(data_perturb, batch_size=256, shuffle=True)\n",
        "\n",
        "print(f\"OOD dataset size: {len(perturb_dl.dataset)}\")\n",
        "\n",
        "print(\"OOD dataset:\")\n",
        "plot_samples(data_perturb)"
      ],
      "metadata": {
        "id": "bkJKGj7dp3CX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_stats = []\n",
        "for _ in range(5):\n",
        "  stats = sequential_train(2, train_dl, valid_dl, valid_rm_dl, valid_rc_dl, test_dl, test_rm_dl, test_rc_dl, \n",
        "                          perturb_dl, alpha=1.0, max_epoch=200, lr_max=0.01)\n",
        "  all_stats.append(stats)\n",
        "  print_stats(stats)"
      ],
      "metadata": {
        "id": "lvny2VG6p3FW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments with $\\mathcal{D}_\\text{ood}^{(3)}$"
      ],
      "metadata": {
        "id": "zHYrqop8sm5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_test = mnist_perturb_base\n",
        "cifar_test = cifar_perturb_base\n",
        "\n",
        "X_m_test_0, _ = keep_only_lbls(mnist_test, lbls=[0])\n",
        "X_m_test_1, _ = keep_only_lbls(mnist_test, lbls=[1])\n",
        "X_m_test_0 = format_mnist(X_m_test_0.view(-1, 1, 28, 28))[torch.randperm(len(X_m_test_0))]\n",
        "X_m_test_1 = format_mnist(X_m_test_1.view(-1, 1, 28, 28))[torch.randperm(len(X_m_test_1))]\n",
        "\n",
        "X_c_test_ood, _ = keep_only_lbls(cifar_test, lbls=[0,2,3,4,5,6,7,8])\n",
        "X_c_test_ood = X_c_test_ood[torch.randperm(len(X_c_test_ood))]\n",
        "\n",
        "K = int((len(X_c_test_ood) / len(X_m_test_0)) // 2)\n",
        "X_m_test_0 = torch.cat([X_m_test_0 for _ in range(K)], dim=0)\n",
        "X_m_test_1 = torch.cat([X_m_test_1 for _ in range(K)], dim=0)\n",
        "X_perturb_0ood = torch.cat((X_m_test_0, X_c_test_ood[:len(X_m_test_0)]),  axis=2)\n",
        "X_perturb_1ood = torch.cat((X_m_test_1, X_c_test_ood[-len(X_m_test_1):]),  axis=2)\n",
        "X_perturb = torch.cat((X_perturb_0ood, X_perturb_1ood), dim=0)\n",
        "X_perturb = X_perturb[torch.randperm(len(X_perturb))]\n",
        "\n",
        "data_perturb = torch.utils.data.TensorDataset(X_perturb.to(DEVICE))\n",
        "\n",
        "perturb_dl = torch.utils.data.DataLoader(data_perturb, batch_size=256, shuffle=True)\n",
        "\n",
        "print(f\"OOD dataset size: {len(perturb_dl.dataset)}\")\n",
        "\n",
        "print(\"OOD dataset:\")\n",
        "plot_samples(data_perturb)"
      ],
      "metadata": {
        "id": "nglVCONCfD9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_stats = []\n",
        "for _ in range(5):\n",
        "  stats = sequential_train(2, train_dl, valid_dl, valid_rm_dl, valid_rc_dl, test_dl, test_rm_dl, test_rc_dl, \n",
        "                          perturb_dl, alpha=0.08, max_epoch=200, lr_max=0.01)#, alpha=0.05, max_epoch=200, lr_max=0.01)\n",
        "  all_stats.append(stats)\n",
        "  print_stats(stats)"
      ],
      "metadata": {
        "id": "hCRhrFqAIKdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AznK3tuL4oSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Q86G-RKJ4oUN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}