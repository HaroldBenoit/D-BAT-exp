{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wilds\n",
    "from wilds.datasets.waterbirds_dataset import WaterbirdsDataset\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_only_waterbirds_dataset(dataset:WaterbirdsDataset) -> WaterbirdsDataset:\n",
    "    train_split_mask = dataset.split_array == dataset.split_dict[\"train\"]\n",
    "    train_split_idx = np.where(train_split_mask)[0]\n",
    "\n",
    "    train_metadata_array = dataset.metadata_array[train_split_mask,:]\n",
    "\n",
    "    #(train_metadata_array[:,0].numpy() == train_metadata_array[:,1].numpy()).mean()\n",
    "    spurious = (train_metadata_array[:,0].numpy() == train_metadata_array[:,1].numpy())\n",
    "\n",
    "    non_spurious_train_split_idx = train_split_idx[~spurious]\n",
    "\n",
    "    dataset.split_array[non_spurious_train_split_idx] = -1\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'majority_only_waterbirds_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c00501dd02fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWaterbirdsDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"datasets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmajority_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmajority_only_waterbirds_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdata_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdata_test\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'majority_only_waterbirds_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "majority_only = True\n",
    "dataset = WaterbirdsDataset(root_dir=\"datasets\")\n",
    "if majority_only:\n",
    "    dataset = majority_only_waterbirds_dataset(dataset)\n",
    "data_train = dataset.get_subset(\"train\")\n",
    "data_test  = dataset.get_subset(\"test\")\n",
    "data_valid = dataset.get_subset(\"val\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.metadata_fields.index('background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 0, 'y': 1}\n",
      "{'x': 1, 'y': 2}\n",
      "{'x': 2, 'y': 3}\n"
     ]
    }
   ],
   "source": [
    "def f():\n",
    "    for i in range(3):\n",
    "        yield {\"x\":i , \"y\":i+1}\n",
    "\n",
    "for x in f():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "saved_data_train_path = \"./datasets/office_home_train.pt\"\n",
    "data_train = torch.load(saved_data_train_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, random_split, Subset\n",
    "import random\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "test_dl = DataLoader(data_train, batch_size=512, worker_init_fn=seed_worker, generator=g,shuffle=False)\n",
    "\n",
    "def dl_to_sampler(dl):\n",
    "    dl_iter = iter(dl)\n",
    "    def sample():\n",
    "        nonlocal dl_iter\n",
    "        try:\n",
    "            return next(dl_iter)\n",
    "        except StopIteration:\n",
    "            dl_iter = iter(dl)\n",
    "            return next(dl_iter)\n",
    "    return sample\n",
    "\n",
    "perturb_sampler = dl_to_sampler(test_dl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Linear(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "a =  defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-8d6a6baa0652>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got NoneType"
     ]
    }
   ],
   "source": [
    "torch.cat((None,a)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc0797ed5014d8db5c582c8811a9204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)lve/main/config.json', max=454.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f4d409085349ae821af75018a90e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading pytorch_model.bin', max=343268597.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at facebook/dino-vitb16 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoImageProcessor, ViTForImageClassification\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\"facebook/dino-vitb16\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7842, 0.4327]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier(torch.ones((1,768)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.load(\"/datasets/home/hbenoit/D-BAT-exp/test_precompute/waterbird/perturb=ood_is_test/resnet50_pretrained=True/ep[2]/ep=[2]_lrmax=0.001_alpha=0.1_dataset=waterbird_model=resnet50_pretrained=True_scheduler=none_seed=0_opt=sgd_ensemble_size=2_no_diversity=False/probs_perturb_batch0.tmp\")\n",
    "\n",
    "a.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ckpt.pt',\n",
       " 'probs_perturb_batch2.tmp',\n",
       " 'probs_perturb_batch3.tmp',\n",
       " 'probs_perturb_batch4.tmp',\n",
       " 'probs_perturb_batch5.tmp',\n",
       " 'probs_perturb_batch6.tmp',\n",
       " 'probs_perturb_batch7.tmp',\n",
       " 'probs_perturb_batch8.tmp',\n",
       " 'probs_perturb_batch9.tmp',\n",
       " 'probs_perturb_batch0.tmp',\n",
       " 'probs_perturb_batch1.tmp']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/datasets/home/hbenoit/D-BAT-exp/test_precompute/waterbird/perturb=ood_is_test/resnet50_pretrained=True/ep[2]/ep=[2]_lrmax=0.001_alpha=0.1_dataset=waterbird_model=resnet50_pretrained=True_scheduler=none_seed=0_opt=sgd_ensemble_size=2_no_diversity=False\"\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "list(glob.glob(os.path.join(path, \"probs_perturb*.tmp\")))\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/datasets/home/hbenoit/D-BAT-exp/test_precompute/waterbird/perturb=ood_is_test/resnet50_pretrained=True/ep[2]/ep=[2]_lrmax=0.001_alpha=0.1_dataset=waterbird_model=resnet50_pretrained=True_scheduler=none_seed=0_opt=sgd_ensemble_size=2_no_diversity=False/probs_perturb*'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(path, \"probs_perturb*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52, 65])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros((3, 52, 65))\n",
    "b= torch.ones((52,65)).unsqueeze(0)\n",
    "\n",
    "torch.cat((a,b))[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "j=-1\n",
    "for i in range(20):\n",
    "    j = (j+1)%18\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "a= defaultdict(list)\n",
    "for i in range(2):\n",
    "    for j in range(18):\n",
    "        item = perturb_sampler()[0][0][0][0][0].item()\n",
    "        a[i].append(item)\n",
    "\n",
    "a[0] == a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "for batch in test_dl:\n",
    "    print(\"hello\")\n",
    "    i+=1\n",
    "\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4357, 3, 90, 90])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.tensors[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2457, 3, 90, 90])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import default_generator, randperm\n",
    "indices = randperm(4357, generator=torch.Generator().manual_seed(42)).tolist()\n",
    "\n",
    "data_test.tensors[0][indices[1900:]].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13161])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((data_train.tensors[1],data_test.tensors[1])).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-96181b767cd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tensor' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "np.sum(tensor([ True,  True,  True, False, False, False]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stats(data):\n",
    "\n",
    "    spurious = (data.metadata_array[:,0].numpy() == data.metadata_array[:,1].numpy())\n",
    "    confounder_strength = spurious.mean()\n",
    "\n",
    "    print(f\"Confounder_strength = {confounder_strength:.3f}\")\n",
    "    \n",
    "    return confounder_strength\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_only(data):\n",
    "\n",
    "    spurious = (data.metadata_array[:,0].numpy() == data.metadata_array[:,1].numpy())\n",
    "\n",
    "    spurious_idx= np.arange(len(data))[spurious]\n",
    "\n",
    "    return data[spurious_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
